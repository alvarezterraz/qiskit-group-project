{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7b938b",
   "metadata": {},
   "source": [
    "# Quantum Neural Network Image Classifier\n",
    "\n",
    "The present project aims to apply quantum kernels implemented with IBM’s quantum \n",
    "computing framework, Qiskit, to classify simple image patterns. Specifically, distinguishing \n",
    "between images of circles and crosses, each represented as 8x8 pixel images.\n",
    "\n",
    "The central objective of this project is to leverage quantum kernel estimation, an innovative \n",
    "method that encodes classical data into quantum states to exploit quantum computational \n",
    "advantages, potentially enhancing classification accuracy or reducing computational \n",
    "complexity compared to classical approaches.\n",
    "\n",
    "## Data Base\n",
    "\n",
    "The initial stage involves the creation of an image dataset consisting of circles and crosses. This dataset will comprise a total of 60 images, subdivided into **40 training images** (20 circles and 20 crosses) and **20 testing images** (10 circles and 10 crosses). To construct this dataset, we developed the `symbols_maker.py` software, which facilitates the manual generation of freehand-drawn images on an 8x8 pixel grid. Subsequently, these images are automatically converted into binary vectors (`crosses.csv` and `circles.csv`), enabling their processing by the neural network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bdae2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 40 samples, 40 labels\n",
      "Test set:  20 samples, 20 labels\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess both CSVs\n",
    "import pandas as pd\n",
    "df_cross  = pd.read_csv('crosses.csv', header=None)\n",
    "df_circle = pd.read_csv('circles.csv', header=None)\n",
    "\n",
    "# Rename last column to 'Label' and map\n",
    "df_cross.rename(columns={df_cross.columns[-1]: 'Label'}, inplace=True)\n",
    "df_cross['Label']  = df_cross['Label'].map({1: 'Cross', 0: 'Circle'})\n",
    "df_circle.rename(columns={df_circle.columns[-1]: 'Label'}, inplace=True)\n",
    "df_circle['Label'] = df_circle['Label'].map({1: 'Cross', 0: 'Circle'})\n",
    "\n",
    "# Reorder columns so 'Label' is first (avoid in‐place slice assignment)\n",
    "cols_cross  = ['Label'] + [c for c in df_cross.columns  if c != 'Label']\n",
    "cols_circle = ['Label'] + [c for c in df_circle.columns if c != 'Label']\n",
    "df_cross  = df_cross[cols_cross]\n",
    "df_circle = df_circle[cols_circle]\n",
    "\n",
    "# Split each into first 20 rows (train) and last 10 rows (test)\n",
    "train_cross, test_cross   = df_cross.iloc[:20], df_cross.iloc[20:]\n",
    "train_circle, test_circle = df_circle.iloc[:20], df_circle.iloc[20:]\n",
    "\n",
    "# Combine train/test sets\n",
    "train_df = pd.concat([train_cross, train_circle], ignore_index=True)\n",
    "test_df  = pd.concat([test_cross,  test_circle ], ignore_index=True)\n",
    "\n",
    "# Extract features and labels\n",
    "data_train   = train_df.drop('Label', axis=1).values\n",
    "labels_train = train_df['Label'].values\n",
    "data_test    = test_df .drop('Label', axis=1).values\n",
    "labels_test  = test_df ['Label'].values\n",
    "\n",
    "print(f\"Train set: {len(data_train)} samples, {len(labels_train)} labels\")\n",
    "print(f\"Test set:  {len(data_test)} samples, {len(labels_test)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e5d9d",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction & Qubit Count\n",
    "\n",
    "The following steps aim to reduce the 8×8 image data (64 features) to a smaller set of principal components and map them to qubits for quantum kernel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "511839e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 21 components, explaining 95.53% variance.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "train_scaled = scaler.fit_transform(data_train)\n",
    "test_scaled = scaler.transform(data_test)\n",
    "\n",
    "# Fit PCA to training data\n",
    "pca = PCA(n_components=0.95)\n",
    "train_pca = pca.fit_transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "# Examine explained variance and component count\n",
    "n_components = pca.n_components_\n",
    "explained_variance = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Selected {n_components} components, explaining {explained_variance:.2%} variance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd325301",
   "metadata": {},
   "source": [
    "## Maping the qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32258e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap\n",
    "# Se podría usar ZFeatureMap o ZZFeatureMap, habría que analizarlo.\n",
    "feature_map = ZZFeatureMap(\n",
    "    feature_dimension=n_components,\n",
    "    reps=2,\n",
    "    entanglement='full'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a046c20",
   "metadata": {},
   "source": [
    "## Kernel Circuit Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a06f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "#from qiskit.utils import QuantumInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00218655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an [n1 x n2] kernel matrix by measuring the all-zero probability of the overlap circuit.\n",
    "def compute_kernel_matrix(X1, X2, feature_map, backend, shots=1024):\n",
    "    n1, n2 = len(X1), len(X2)\n",
    "    kernel = np.zeros((n1, n2))\n",
    "    for i, x1 in enumerate(X1):\n",
    "        for j, x2 in enumerate(X2):\n",
    "            # Build overlap circuit: U(x1) · U(x2)^{-1}\n",
    "            qc1 = feature_map.assign_parameters(x1)\n",
    "            qc2 = feature_map.assign_parameters(x2)\n",
    "            overlap = qc1.compose(qc2.inverse())\n",
    "\n",
    "            # Add measurements to capture counts\n",
    "            overlap.measure_all()\n",
    "\n",
    "            # Transpile for performance\n",
    "            transpiled = transpile(overlap, backend=backend, optimization_level=3)\n",
    "\n",
    "            # Execute and get counts\n",
    "            job = backend.run(transpiled, shots=shots)\n",
    "            result = job.result()\n",
    "            counts = result.get_counts()\n",
    "\n",
    "            # Probability of |0...0>\n",
    "            p0 = counts.get('0' * feature_map.num_qubits, 0) / shots\n",
    "            kernel[i, j] = p0\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = AerSimulator()\n",
    "# For hardware: replace with your IBMProvider sampler\n",
    "\n",
    "# Compute training kernel (symmetric; could optimize by half)\n",
    "K_train = compute_kernel_matrix(train_pca, train_pca, feature_map, backend)\n",
    "\n",
    "# Compute test kernel (full)\n",
    "K_test = compute_kernel_matrix(test_pca, train_pca, feature_map, backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_train shape: (40, 40)\n",
      "K_test shape: (20, 40)\n",
      "[[0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.00097656 0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.00097656 0.         0.         0.         0.00097656\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.00097656 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00097656 0.         0.00195312 0.         0.00097656 0.\n",
      "  0.         0.         0.         0.         0.00097656 0.\n",
      "  0.00097656 0.         0.         0.00097656]\n",
      " [0.00097656 0.         0.00097656 0.00195312 0.         0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.00195312 0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00097656]\n",
      " [0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00195312 0.\n",
      "  0.00097656 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         0.00097656 0.00097656 0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.00097656 0.         0.\n",
      "  0.00097656 0.         0.         0.         0.00097656 0.\n",
      "  0.00195312 0.         0.         0.00097656]\n",
      " [0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.         0.         0.00195312 0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00097656 0.         0.         0.         0.         0.00097656\n",
      "  0.         0.00097656 0.00097656 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.         0.00097656 0.        ]\n",
      " [0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00097656 0.00097656 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00097656 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.00097656 0.         0.         0.         0.00195312 0.\n",
      "  0.00097656 0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.00097656]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.00195312 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00097656 0.\n",
      "  0.         0.         0.00097656 0.         0.00097656 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00195312 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.         0.         0.00097656 0.00195312 0.00097656\n",
      "  0.         0.00097656 0.         0.00097656]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00195312 0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00097656 0.         0.         0.        ]\n",
      " [0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.00097656 0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00097656 0.         0.        ]\n",
      " [0.00097656 0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.00097656 0.         0.         0.\n",
      "  0.         0.00097656 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00195312\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00097656 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00195312 0.         0.         0.00097656 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00195312 0.         0.         0.\n",
      "  0.00292969 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00097656 0.00097656\n",
      "  0.         0.         0.         0.         0.         0.00097656\n",
      "  0.00097656 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00097656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00097656 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00195312 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"K_train shape:\", K_train.shape)\n",
    "print(\"K_test shape:\", K_test.shape)\n",
    "print(K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9ba36",
   "metadata": {},
   "source": [
    "## SVM Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f43bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.00%\n",
      "Confusion Matrix:\n",
      "[[ 0  5]\n",
      " [ 0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       0.00      0.00      0.00         5\n",
      "       Cross       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.38      0.50      0.43        20\n",
      "weighted avg       0.56      0.75      0.64        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 6.1 Train the SVM using the precomputed training kernel\n",
    "svc = SVC(kernel=\"precomputed\")\n",
    "svc.fit(K_train, labels_train)\n",
    "\n",
    "# 6.2 Predict on the test kernel\n",
    "labels_pred = svc.predict(K_test)\n",
    "\n",
    "# 6.3 Evaluation metrics\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "conf_mat = confusion_matrix(labels_test, labels_pred)\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654db0dd",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {'Circle', 'Cross'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compute ROC curve\u001b[39;00m\n\u001b[32m     19\u001b[39m labels_scores = svc.decision_function(K_test)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m fpr, tpr, _ = \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m roc_auc = auc(fpr, tpr)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Plot ROC curve\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1150\u001b[39m, in \u001b[36mroc_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1047\u001b[39m     {\n\u001b[32m   1048\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1057\u001b[39m     y_true, y_score, *, pos_label=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1058\u001b[39m ):\n\u001b[32m   1059\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[32m   1060\u001b[39m \n\u001b[32m   1061\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m \u001b[33;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[32m   1149\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[32m   1155\u001b[39m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[32m   1156\u001b[39m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[32m   1162\u001b[39m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:835\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    832\u001b[39m     y_score = y_score[nonzero_weight_mask]\n\u001b[32m    833\u001b[39m     sample_weight = sample_weight[nonzero_weight_mask]\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m pos_label = \u001b[43m_check_pos_label_consistency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# make y_true a boolean vector\u001b[39;00m\n\u001b[32m    838\u001b[39m y_true = y_true == pos_label\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\artur\\Documents\\Qiskit R2P\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2641\u001b[39m, in \u001b[36m_check_pos_label_consistency\u001b[39m\u001b[34m(pos_label, y_true)\u001b[39m\n\u001b[32m   2633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m classes.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mOUS\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[32m   2634\u001b[39m         np.array_equal(classes, [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m   2635\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m np.array_equal(classes, [-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m   (...)\u001b[39m\u001b[32m   2638\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m np.array_equal(classes, [\u001b[32m1\u001b[39m])\n\u001b[32m   2639\u001b[39m     ):\n\u001b[32m   2640\u001b[39m         classes_repr = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mrepr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes.tolist()])\n\u001b[32m-> \u001b[39m\u001b[32m2641\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2642\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my_true takes value in \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclasses_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m and pos_label is not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2643\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified: either make y_true take value in \u001b[39m\u001b[33m{\u001b[39m\u001b[33m0, 1} or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2644\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m-1, 1} or pass pos_label explicitly.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2645\u001b[39m         )\n\u001b[32m   2646\u001b[39m     pos_label = \u001b[32m1\u001b[39m\n\u001b[32m   2648\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pos_label\n",
      "\u001b[31mValueError\u001b[39m: y_true takes value in {'Circle', 'Cross'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(labels_test, labels_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plt.imshow(conf_mat)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks([0, 1], ['Circles', 'Crosses'])\n",
    "plt.yticks([0, 1], ['Circles', 'Crosses'])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve\n",
    "labels_scores = svc.decision_function(K_test)\n",
    "fpr, tpr, _ = roc_curve(labels_test, labels_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # chance line\n",
    "plt.title(f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
